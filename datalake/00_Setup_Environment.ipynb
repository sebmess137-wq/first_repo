{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f48bc84f-1c8a-4ad7-bc6f-b4e4ab2a4e6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "2bKfHvgCG8af"
   },
   "source": [
    "# Setup Environment for Lakeflow Declarative Pipelines\n",
    "\n",
    "This notebook sets up the environment for the Lakeflow Declarative Pipelines course.\n",
    "\n",
    "It will:\n",
    "- Create catalog: `ldp_demo`\n",
    "- Create schema: `ldp_schema`\n",
    "- Create volume: `raw` within the schema\n",
    "- Create folders (customers, orders, status) in the volume\n",
    "- Copy sample data files to the volume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82fbbcdf-7696-4fc2-869f-9f33dc5e1455",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "TDu_AjHsG8aj"
   },
   "outputs": [],
   "source": [
    "# Define catalog, schema, and volume names\n",
    "CATALOG_NAME = 'cetpa_external_catalog'\n",
    "SCHEMA_NAME = 'ldp_schema'\n",
    "VOLUME_NAME = 'raw'\n",
    "\n",
    "# Define the base volume path\n",
    "VOLUME_PATH = f'/Volumes/{CATALOG_NAME}/{SCHEMA_NAME}/{VOLUME_NAME}'\n",
    "\n",
    "print(f'Catalog: {CATALOG_NAME}')\n",
    "print(f'Schema: {SCHEMA_NAME}')\n",
    "print(f'Volume: {VOLUME_NAME}')\n",
    "print(f'Volume Path: {VOLUME_PATH}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f38aa16-14eb-4c55-8925-547b0b9349b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "x2HGiiJMG8al"
   },
   "source": [
    "## Step 1: Create Catalog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b670b940-fdd0-42bf-90cd-2de5a1df8fa1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "ExCK0ihGG8an"
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Create catalog if it doesn't exist\n",
    " CREATE CATALOG IF NOT EXISTS cetpa_external_catalog;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1c94022-76cc-4067-bf84-9728be1c0f67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "uGY2exDcG8ao"
   },
   "source": [
    "## Step 2: Create Schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31c29084-8981-48dd-a2b0-5cc1d7534ad2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "oF5VGdWTG8ap"
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Create schema within the catalog\n",
    "CREATE SCHEMA IF NOT EXISTS cetpa_external_catalog.ldp_schema;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d951d91-ec7e-4377-b344-10196c2ebe48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "OdbsqvlWG8ar"
   },
   "source": [
    "## Step 3: Create Volume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9167acaa-7f46-4f8f-95f5-5e1b11cd36c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "PIDAWLbQG8au"
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Create volume within the schema\n",
    "CREATE VOLUME IF NOT EXISTS cetpa_external_catalog.ldp_schema.raw;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84d123ac-4e55-4835-bdf3-10642856f575",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "fFeGqSTlG8aw"
   },
   "source": [
    "## Step 4: Create Directories in Volume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a50cd12-0e04-48af-8cbc-b40ea1b9475c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "odXXePsvG8ax"
   },
   "outputs": [],
   "source": [
    "def create_directory_in_volume(volume_path: str, folder_names: list):\n",
    "    '''\n",
    "    Creates multiple directories in the specified volume path using dbutils.fs.\n",
    "\n",
    "    Parameters:\n",
    "    - volume_path (str): The base volume path\n",
    "    - folder_names (list): A list of folder names to create\n",
    "    '''\n",
    "    print('----------------------------------------------------------------------------------------')\n",
    "    for folder in folder_names:\n",
    "        folder_path = f'{volume_path}/{folder}'\n",
    "        try:\n",
    "            # Try to list the directory to check if it exists\n",
    "            dbutils.fs.ls(folder_path)\n",
    "            print(f'Directory {folder_path} already exists. No action taken.')\n",
    "        except:\n",
    "            # Directory doesn't exist, create it\n",
    "            dbutils.fs.mkdirs(folder_path)\n",
    "            print(f'Creating folder: {folder_path}')\n",
    "    print('----------------------------------------------------------------------------------------\\n')\n",
    "\n",
    "# Create folders for customers, orders, and status\n",
    "create_directory_in_volume(VOLUME_PATH, ['customers', 'orders', 'status'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9842a876-9542-4fc7-b7ab-2cebaede5da5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "LpySLVuNG8ay"
   },
   "source": [
    "## Step 5: Delete Existing Files (if resetting)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fdea817-a2bf-41a0-8c31-dd7b102e0dc8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "l2Ku3XefG8ay"
   },
   "outputs": [],
   "source": [
    "def delete_source_files(source_path: str):\n",
    "    \"\"\"\n",
    "    Deletes all files in the specified source volume.\n",
    "\n",
    "    Parameters:\n",
    "    - source_path: The path to the volume containing the files to delete\n",
    "    \"\"\"\n",
    "    import os\n",
    "\n",
    "    print(f'\\nSearching for files in {source_path} to delete...')\n",
    "    if os.path.exists(source_path):\n",
    "        list_of_files = sorted(os.listdir(source_path))\n",
    "    else:\n",
    "        list_of_files = None\n",
    "\n",
    "    if not list_of_files:\n",
    "        print(f'No files found in {source_path}.\\n')\n",
    "    else:\n",
    "        for file in list_of_files:\n",
    "            file_to_delete = os.path.join(source_path, file)\n",
    "            print(f'Deleting file: {file_to_delete}')\n",
    "            dbutils.fs.rm(file_to_delete)\n",
    "\n",
    "# Delete existing files if resetting\n",
    "delete_source_files(f'{VOLUME_PATH}/customers/')\n",
    "delete_source_files(f'{VOLUME_PATH}/orders/')\n",
    "delete_source_files(f'{VOLUME_PATH}/status/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "474f6282-ad6f-406d-ae32-d0cd9e24acfb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "wQqKA9ZZG8az"
   },
   "source": [
    "## Step 6: Create Sample JSON Data Files\n",
    "\n",
    "This step creates sample JSON files programmatically based on the course data structure. The files are created directly in your volume without needing to copy from external sources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f6bfe1b-41c0-4a48-b244-f26871d4e618",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "x2l30u4ZG8az"
   },
   "outputs": [],
   "source": [
    "def create_sample_json_files():\n",
    "    \"\"\"\n",
    "    Create sample JSON files based on the course data structure.\n",
    "    This generates realistic sample data matching the course requirements:\n",
    "    - Orders: 174 records (order_id, order_timestamp, customer_id, notifications)\n",
    "    - Status: Multiple status records per order (order_id, order_status, status_timestamp)\n",
    "    - Customers: 939 records (customer_id, name, email, address, city, state, operation, timestamp)\n",
    "    \"\"\"\n",
    "    import json\n",
    "    import random\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    print(\"\\n----------------Creating sample JSON files----------------\")\n",
    "\n",
    "    # Generate sample orders data (174 rows as mentioned in the course)\n",
    "    # Orders structure: order_id, order_timestamp, customer_id, notifications\n",
    "    base_date = datetime(2024, 1, 15, 10, 0, 0)\n",
    "    sample_orders = []\n",
    "    for i in range(174):\n",
    "        order_id = 75000 + i\n",
    "        order_timestamp = (base_date + timedelta(minutes=i*5)).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        customer_id = 1000 + (i % 50)  # Cycle through 50 customers\n",
    "        notifications = random.choice([True, False])\n",
    "        sample_orders.append({\n",
    "            \"order_id\": order_id,\n",
    "            \"order_timestamp\": order_timestamp,\n",
    "            \"customer_id\": customer_id,\n",
    "            \"notifications\": notifications\n",
    "        })\n",
    "\n",
    "    # Generate sample status data\n",
    "    # Status structure: order_id, order_status, status_timestamp\n",
    "    # Multiple statuses per order (placed -> preparing -> on the way -> delivered)\n",
    "    sample_status = []\n",
    "    for order in sample_orders[:50]:  # Create statuses for first 50 orders\n",
    "        order_id = order[\"order_id\"]\n",
    "        base_ts = datetime.strptime(order[\"order_timestamp\"], \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "        # Each order gets multiple status updates\n",
    "        for idx, status in enumerate(['placed', 'preparing', 'on the way', 'delivered']):\n",
    "            status_timestamp = (base_ts + timedelta(hours=idx*2)).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "            sample_status.append({\n",
    "                \"order_id\": order_id,\n",
    "                \"order_status\": status,\n",
    "                \"status_timestamp\": status_timestamp\n",
    "            })\n",
    "\n",
    "    # Add some canceled orders\n",
    "    for i in range(5):\n",
    "        order_id = sample_orders[i*10][\"order_id\"]\n",
    "        base_ts = datetime.strptime(sample_orders[i*10][\"order_timestamp\"], \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        status_timestamp = (base_ts + timedelta(hours=1)).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        sample_status.append({\n",
    "            \"order_id\": order_id,\n",
    "            \"order_status\": \"canceled\",\n",
    "            \"status_timestamp\": status_timestamp\n",
    "        })\n",
    "\n",
    "    # Generate sample customers data (939 customers as mentioned in the course)\n",
    "    # Customers structure: customer_id, name, email, address, city, state, operation, timestamp\n",
    "    first_names = [\"John\", \"Jane\", \"Bob\", \"Alice\", \"Charlie\", \"Diana\", \"Eve\", \"Frank\", \"Grace\", \"Henry\",\n",
    "                   \"Ivy\", \"Jack\", \"Kate\", \"Liam\", \"Mary\", \"Noah\", \"Olivia\", \"Paul\", \"Quinn\", \"Rachel\"]\n",
    "    last_names = [\"Smith\", \"Johnson\", \"Williams\", \"Brown\", \"Jones\", \"Garcia\", \"Miller\", \"Davis\", \"Rodriguez\", \"Martinez\",\n",
    "                  \"Wilson\", \"Anderson\", \"Taylor\", \"Thomas\", \"Hernandez\", \"Moore\", \"Martin\", \"Jackson\", \"Thompson\", \"White\"]\n",
    "    cities_states = [\n",
    "        (\"New York\", \"NY\"), (\"Los Angeles\", \"CA\"), (\"Chicago\", \"IL\"), (\"Houston\", \"TX\"),\n",
    "        (\"Phoenix\", \"AZ\"), (\"Philadelphia\", \"PA\"), (\"San Antonio\", \"TX\"), (\"San Diego\", \"CA\"),\n",
    "        (\"Dallas\", \"TX\"), (\"San Jose\", \"CA\"), (\"Austin\", \"TX\"), (\"Jacksonville\", \"FL\"),\n",
    "        (\"Fort Worth\", \"TX\"), (\"Columbus\", \"OH\"), (\"Charlotte\", \"NC\"), (\"San Francisco\", \"CA\"),\n",
    "        (\"Indianapolis\", \"IN\"), (\"Seattle\", \"WA\"), (\"Denver\", \"CO\"), (\"Boston\", \"MA\")\n",
    "    ]\n",
    "    street_names = [\"Main\", \"Oak\", \"Pine\", \"Elm\", \"Maple\", \"Park\", \"First\", \"Second\", \"Third\", \"Fourth\"]\n",
    "\n",
    "    sample_customers = []\n",
    "    base_customer_date = datetime(2024, 1, 15, 10, 0, 0)\n",
    "\n",
    "    for i in range(939):\n",
    "        customer_id = 1000 + i\n",
    "        first_name = random.choice(first_names)\n",
    "        last_name = random.choice(last_names)\n",
    "        name = f\"{first_name} {last_name}\"\n",
    "        email = f\"{first_name.lower()}.{last_name.lower()}{i}@example.com\"\n",
    "        city, state = random.choice(cities_states)\n",
    "        street_num = random.randint(100, 9999)\n",
    "        street = random.choice(street_names)\n",
    "        address = f\"{street_num} {street} St\"\n",
    "        operation = \"NEW\"  # First file has all NEW operations\n",
    "        timestamp = (base_customer_date + timedelta(seconds=i*10)).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "        sample_customers.append({\n",
    "            \"customer_id\": customer_id,\n",
    "            \"name\": name,\n",
    "            \"email\": email,\n",
    "            \"address\": address,\n",
    "            \"city\": city,\n",
    "            \"state\": state,\n",
    "            \"operation\": operation,\n",
    "            \"timestamp\": timestamp\n",
    "        })\n",
    "\n",
    "    # Write files using dbutils.fs.put (works with volumes, no DBFS root needed)\n",
    "    # Format: newline-delimited JSON (one JSON object per line)\n",
    "    try:\n",
    "        # Orders file\n",
    "        orders_file = f'{VOLUME_PATH}/orders/00.json'\n",
    "        orders_json_lines = [json.dumps(order) for order in sample_orders]\n",
    "        orders_content = '\\n'.join(orders_json_lines)\n",
    "        dbutils.fs.put(orders_file, orders_content, overwrite=True)\n",
    "        print(f'‚úÖ Created orders file: {orders_file} ({len(sample_orders)} records)')\n",
    "\n",
    "        # Status file\n",
    "        status_file = f'{VOLUME_PATH}/status/00.json'\n",
    "        status_json_lines = [json.dumps(status) for status in sample_status]\n",
    "        status_content = '\\n'.join(status_json_lines)\n",
    "        dbutils.fs.put(status_file, status_content, overwrite=True)\n",
    "        print(f'‚úÖ Created status file: {status_file} ({len(sample_status)} records)')\n",
    "\n",
    "        # Customers file\n",
    "        customers_file = f'{VOLUME_PATH}/customers/00.json'\n",
    "        customers_json_lines = [json.dumps(customer) for customer in sample_customers]\n",
    "        customers_content = '\\n'.join(customers_json_lines)\n",
    "        dbutils.fs.put(customers_file, customers_content, overwrite=True)\n",
    "        print(f'‚úÖ Created customers file: {customers_file} ({len(sample_customers)} records)')\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Error creating sample files: {e}')\n",
    "        print('Note: You may need to create JSON files manually.')\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "# Create sample JSON files directly\n",
    "print('\\nüìù Creating sample JSON files for the course...')\n",
    "sample_created = create_sample_json_files()\n",
    "\n",
    "if sample_created:\n",
    "    print('\\n‚úÖ Successfully created all sample JSON files!')\n",
    "    print(f'\\nFiles created in: {VOLUME_PATH}')\n",
    "    print('  - orders/00.json (174 orders)')\n",
    "    print('  - status/00.json (multiple status records)')\n",
    "    print('  - customers/00.json (939 customers)')\n",
    "else:\n",
    "    print('\\n‚ùå Could not create sample files automatically.')\n",
    "    print(f'\\nPlease manually add JSON files to:')\n",
    "    print(f'  - {VOLUME_PATH}/customers/')\n",
    "    print(f'  - {VOLUME_PATH}/orders/')\n",
    "    print(f'  - {VOLUME_PATH}/status/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bddb053-e8a1-49c3-b9a3-b825ecd6d0c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "gmXIry7TG8a1"
   },
   "source": [
    "## Step 7: Verify Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b1c32d6-f90a-4b02-a71f-83bc52e0308c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "7YuMu6tUG8a2"
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Verify catalog exists\n",
    "SHOW CATALOGS LIKE 'cetpa_external_catalog';\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "783537f1-4c17-47b5-b781-a156c7573c55",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "UToCKU-iG8a3"
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Verify schema exists\n",
    "SHOW SCHEMAS IN cetpa_external_catalog LIKE 'ldp_schema';\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39003838-dd28-4752-aa44-d7585201a602",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "vlhAnX-IG8a4"
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Verify volume exists\n",
    "SHOW VOLUMES IN cetpa_external_catalog.ldp_schema LIKE 'raw';\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed8ad4b6-7bee-4c9f-a51d-2a461799adb2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "PBgboOUlG8a5"
   },
   "outputs": [],
   "source": [
    "# Verify folders and files\n",
    "print(f'\\nVerifying volume structure:')\n",
    "print(f'Volume path: {VOLUME_PATH}')\n",
    "print(f'\\nFolders:')\n",
    "for folder in ['customers', 'orders', 'status']:\n",
    "    folder_path = f'{VOLUME_PATH}/{folder}'\n",
    "    try:\n",
    "        files = dbutils.fs.ls(folder_path)\n",
    "        file_list = [f.name for f in files if not f.isDir()]\n",
    "        print(f'  {folder}/: {len(file_list)} file(s)')\n",
    "        if file_list:\n",
    "            for file in sorted(file_list)[:3]:  # Show first 3 files\n",
    "                print(f'    - {file}')\n",
    "    except Exception as e:\n",
    "        print(f'  {folder}/: NOT FOUND or ERROR - {e}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f84494c-9f7b-4c66-b535-ddce07314144",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "BAeTtx0uG8a5"
   },
   "source": [
    "## Setup Complete!\n",
    "\n",
    "Your environment is now configured with:\n",
    "- Catalog: `ldp_demo`\n",
    "- Schema: `ldp_schema`\n",
    "- Volume: `raw` at `/Volumes/ldp_demo/ldp_schema/raw`\n",
    "- Folders: `customers`, `orders`, `status`\n",
    "\n",
    "All tables will be created in the `ldp_demo.ldp_schema` schema.\n",
    "\n",
    "You can now proceed with the course notebooks.\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6232324419377856,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "00_Setup_Environment",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
